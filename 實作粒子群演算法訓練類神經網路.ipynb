{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e91a43-4f20-4a46-999a-d0c6a8477e82",
   "metadata": {},
   "source": [
    "# 實作PSO訓練類神經網路\n",
    "\n",
    "經過ch1~5的介紹，相信要編寫一個粒子群演算法的優化器並不是難事。比較需要知道的是優化器如何在`trian_tool.train_batch`中運作的，而優化器需要符合什麼條件？\n",
    "\n",
    "其實只需要編寫`__call__`方法的類，都可以作為優化器，在`train_batch`函數運作時會通過`__call__`方法傳入一個`net_pool`的實例，而優化器只需要回傳一個優化好的池即可。\n",
    "\n",
    "下面是一個PSO(粒子群演算法)的優化器實作範例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "911eef83-c0f4-4642-aea9-87f6261d6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyto import train_tool as train\n",
    "import random\n",
    "\n",
    "class PSO:\n",
    "    def __init__(self, inertia_w=0.99, c1=0.5, c2=0.5, init_v_pool=None):\n",
    "        self.pbest_pool=None\n",
    "        self.v_pool=init_v_pool # 初始速度: 如果沒有給定，則在第一次優化時再初始化\n",
    "        self.w=inertia_w\n",
    "        self.c1=c1\n",
    "        self.c2=c2\n",
    "        \n",
    "    def __call__(self, pool):\n",
    "        # 如果是第一次優化，先初始化\n",
    "        if self.pbest_pool is None: self.pbest_pool=pool.copy()\n",
    "        if self.v_pool is None: self.v_pool=train.unit_particle(pool)\n",
    "        \n",
    "        # 更新經歷過的最好位置\n",
    "        for idx in range(len(self.pbest_pool)):\n",
    "            if pool.loss.real[idx]<self.pbest_pool.loss.real[idx]:\n",
    "                self.pbest_pool.real_net[idx]=pool.net.real[idx]\n",
    "        \n",
    "        # 取得全域所經歷最好位置\n",
    "        gbest_net=self.pbest_pool.net[0]\n",
    "        \n",
    "        # 計算各項的速度\n",
    "        momentum_v=self.w*self.v_pool\n",
    "        cognition_v=self.c1*random.random()*(self.pbest_pool-pool)\n",
    "        social_v=self.c2*random.random()*pool.pool_apply(lambda n: gbest_net-n)\n",
    "        \n",
    "        # 更新速度\n",
    "        self.v_pool=momentum_v+cognition_v+social_v\n",
    "        \n",
    "        # 更新池中各粒子的位置\n",
    "        return pool+self.v_pool\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec6ad7-d5dd-4c11-b10e-9db4b23a830c",
   "metadata": {},
   "source": [
    "下面我們就用這個優化器來訓練我們的神經網路，我們請到我們的老朋友鳶尾花資料集作為訓練資料:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "394a3ca4-c1cd-4635-8fad-7fa136fe16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris=datasets.load_iris()     # 載入資料\n",
    "feature=iris.data             # 輸入的特徵資料\n",
    "label=np.eye(3)[iris.target]  # 預測的類別資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82035c9-47e9-447e-9ae3-78b887513894",
   "metadata": {},
   "source": [
    "下面我們建立我們的網路:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd97656-26cc-4cef-adf6-3bd0f39e2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyto import net_tool as to\n",
    "from nyto import layer\n",
    "from nyto import unit_function as uf\n",
    "\n",
    "(nn, node)=to.new_net(\n",
    "    layer1=layer.new_nn_layer((4,12)),  # 加入模型節點: layer1(單層神經網路)\n",
    "    layer2=layer.new_nn_layer((12,3))   # 加入模型節點: layer2(單層神經網路)\n",
    ")\n",
    "\n",
    "node.l1_output=node.data_input>>node.layer1>>uf.tanh()\n",
    "node.pre=node.l1_output>>node.layer2>>uf.softmax()\n",
    "\n",
    "node.loss=uf.cross_entropy(node.pre, node.data_label)\n",
    "node.acc=uf.accuracy(node.pre, node.data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7f72b-add1-4d27-a307-5d0783c7144c",
   "metadata": {},
   "source": [
    "然後我們來分割資料並製作批啟動器:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d859e3bf-74f7-4bce-84b6-2fb2b4593c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list=to.batch_launcher(\n",
    "    nn=nn,\n",
    "    get={node.pre, node.loss, node.acc},\n",
    "    batch_push={'data_input':feature, 'data_label':label},\n",
    "    batch_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29cb48-da09-4a56-b8f3-53dbc56e2a72",
   "metadata": {},
   "source": [
    "在訓練的時候我們只需要loss和acc，所以將其分離出來:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4208eb19-9a88-4d4d-bda0-c7612eaa3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_node_list=[n['loss'] for n in node_list]\n",
    "acc_node_list=[n['acc'] for n in node_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5f428-8f5b-4cd3-ba71-d389a059e87f",
   "metadata": {},
   "source": [
    "最後建立我們的池跟優化器:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93224efb-06e8-4fcf-a5dd-6aed7ab25787",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool=train.new_pool(loss_node_list[0], pool_size=20)\n",
    "opt=PSO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf86b4-54ee-4493-905c-f47a3f94d850",
   "metadata": {},
   "source": [
    "下面可以開始訓練了，我們打印出每個step的loss和accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf59fbf9-18e9-426a-8bb7-3e1718a5ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0306472860131364 0.35\n",
      "1 0.938042095210885 0.9\n",
      "2 0.9100661461571733 0.6\n",
      "3 0.790694814382637 0.65\n",
      "4 0.4552266222837882 0.8\n",
      "5 0.9441212580689028 0.55\n",
      "6 1.175445814248707 0.65\n",
      "7 0.278880016367826 0.85\n",
      "7 0.278880016367826 0.85\n"
     ]
    }
   ],
   "source": [
    "for (t, new_pool, opt) in train.train_batch(loss_node_list, pool, opt):\n",
    "    (epoch, step)=t\n",
    "    \n",
    "    best_loss=new_pool.loss[0]\n",
    "    best_net=new_pool.net[0]\n",
    "    \n",
    "    acc_node_id=acc_node_list[step].node_id\n",
    "    best_acc=to.get(best_net[acc_node_id])\n",
    "    \n",
    "    print(step, best_loss, best_acc)\n",
    "    \n",
    "    new_pool # 可以在訓練過程中保存池\n",
    "    opt      # 也可以在訓練過程中調整優化器的參數\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f0a7f-035e-43a6-ac36-f773ac8bf4aa",
   "metadata": {},
   "source": [
    "***\n",
    "*END*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
