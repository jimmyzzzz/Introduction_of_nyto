{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aea0e6-76e0-4651-84d0-3ffd64c192a6",
   "metadata": {},
   "source": [
    "# ch5 粒子與優化\n",
    "\n",
    "相信在前面的章節已經介紹了很多有關於節點的內容，甚至還引入了層模型的觀念。所謂層模型就是一種可以優化的單元，甚至網路本身也可以看作是層模型。\n",
    "\n",
    "但其實網路和層模型都是屬於 **粒子(particle)** 底下的一種而已，那麼什麼是粒子呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96817e60-0b26-4a68-a0bd-a45a416be220",
   "metadata": {},
   "source": [
    "## 粒子\n",
    "\n",
    "在nyto中，所有可優化的東西都是粒子，也就是說網路本身是粒子，`nyto.layer`底下的模型也是粒子。在nyto中所有針對網路或是模型的優化行為，本質上是針對粒子的運算行為。若是該模型不是粒子或是該模型雖然是粒子但不能運算，則該模型不能被優化。\n",
    "\n",
    "下面我們就來看看如何對粒子進行運算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8949af97-443d-48d6-9c1d-5103e52a5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyto import layer\n",
    "from nyto import net_tool as to\n",
    "from nyto.net_tool import get\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddbbf0-3ff0-459c-8b6f-2fab5fa01140",
   "metadata": {},
   "source": [
    "### 粒子對數字的運算\n",
    "\n",
    "粒子對數字的運算結果會是一個粒子，粒子對數字的運算可以簡單依循下面的規則:\n",
    "1. 如果是網路對數字的運算，則網路內模型單元中的所有粒子對該數字做相同的運算\n",
    "2. 如果是層模型對數字的運算，則網路內的參數對該數字做相同的運算\n",
    "\n",
    "**層模型對數字的運算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbd8311-96b4-4cad-a27e-ea4cb8524c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((2, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = layer.new_variable_layer((2,2))\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a02cfe-bc9a-4dff-954a-71719489d756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((2, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10819b5e-83a5-466f-be2e-81a0757a6309",
   "metadata": {},
   "source": [
    "**網路對數字的運算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433717d9-3e4b-4234-9597-3771900ecdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn, node = to.new_net(\n",
    "    particle_and_mod=layer.new_nn_layer((2,2)),\n",
    "    particle_but_not_a_mod=to.add_data(layer.new_variable_layer((2,2))),\n",
    "    mod_but_not_a_particle=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7fa564-333e-4c20-a00a-dd31d74d12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn = nn + 1\n",
    "new_node = to.create_connecter(new_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a09c4b5-d77e-43e4-b464-0a6349f0b390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn_layer((2, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(new_node.particle_and_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5752ae4-ef82-408e-9d3b-1f6b7703c0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((2, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(new_node.particle_but_not_a_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8da040-47f9-4182-af02-272a79795f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(new_node.mod_but_not_a_particle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cdbb8-d329-4fb5-bf56-ba26fc8ffa9d",
   "metadata": {},
   "source": [
    "### 粒子對粒子的運算\n",
    "\n",
    "粒子對粒子的運算結果會是一個粒子，粒子對粒子的運算可以簡單依循下面的規則:\n",
    "1. 如果是網路對網路的運算: 則雙方模型單元中相同名字的粒子做同樣的運算。\n",
    "2. 如果是層模型對層模型的運算: 則雙方相對位置的參數做同樣的運算。\n",
    "3. 不要進行網路對層模型的運算。\n",
    "\n",
    "基本上，雖然理論上支持網路跟層模型的運算，但是實際上並不能成功。不同網路間的運算成立條件非常嚴格，通常兩個網路必須擁有相同的結構，基本上是來自同一個網路的通過計算產生的網路才能互相計算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341ead7-80ba-4c53-ab17-8038af6d19df",
   "metadata": {},
   "source": [
    "**層模型對層模型的運算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0a77850-7c84-4e18-aa24-7dc571ed4d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(variable_layer((3, 3)), variable_layer((3, 3)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1=layer.np_to_variable_layer(np.arange(9).reshape(3,3))\n",
    "var2=layer.np_to_variable_layer(np.arange(9,18).reshape(3,3))\n",
    "\n",
    "var1, var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23cfa05c-1181-425a-99b5-b3e937ed0b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((3, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1+var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7367491-5ab2-4903-803c-1d7f51ab2f8d",
   "metadata": {},
   "source": [
    "**網路對網路的運算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ffea34f-1589-46af-9f88-01e2efb67fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "nn1, node1 = to.new_net(\n",
    "    mod_but_not_a_particle=1,\n",
    "    particle_but_not_a_mod=to.add_data(layer.np_to_variable_layer(np.arange(3))),\n",
    "    particle_and_mod=layer.np_to_variable_layer(np.arange(4).reshape(2,2))\n",
    ")\n",
    "\n",
    "nn2, node2 = to.new_net(\n",
    "    mod_but_not_a_particle=2,\n",
    "    particle_but_not_a_mod=to.add_data(layer.np_to_variable_layer(np.arange(3,6))),\n",
    "    particle_and_mod=layer.np_to_variable_layer(np.arange(4,8).reshape(2,2))\n",
    ")\n",
    "\n",
    "new_nn = nn1 + nn2\n",
    "new_node = to.create_connecter(new_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92bdcd40-6b63-4ef0-9d0e-64044f04343a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(new_node.mod_but_not_a_particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663248da-4309-41a2-8f84-948ed3dad357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((3,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(new_node.particle_but_not_a_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b678cb-f71b-47f5-9d78-6dedd4ba5154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((2, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(new_node.particle_and_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b08b8d-98ae-4b61-a6a2-08baddbc0e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "可以發現當網路內有非粒子的模型時，粒子繼承來自運算符號左邊的粒子的模型。\n",
    "\n",
    "### 粒子運算的繼承關係\n",
    "\n",
    "當粒子發生運算時，會產生一個新的粒子，新的粒子會繼承原先粒子中的一些資訊。但繼承的方式會有所不同，具體如下:\n",
    "1. 對於資料單元: 與原先粒子共用同一個資料單元\n",
    "2. 對於模型單元: 複製一份模型單元\n",
    "3. 節點資訊: 與原先粒子共用\n",
    "\n",
    "所以對於函數模型或是訓練用的資料，這些不會被修改的單元，我們要放在資料單元與延生粒子共用。而對於模型參數這些粒子自己獨有的部份，我們要放在模型單元。這不僅僅只是為了節省空間，還可以提升速度。\n",
    "\n",
    "這不僅僅適用於粒子運算，網路優化也是一樣。因為網路優化也是使用粒子運算實現的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600475af-6342-40bc-976a-9c3ad65c7be7",
   "metadata": {},
   "source": [
    "## 隨機粒子\n",
    "\n",
    "當我們需要讓粒子的參數增加一些隨機性的時候，我們可以讓粒子與一個具有隨機性的粒子進行粒子運算。下面提供了常見的產生隨機性的粒子的函數，函數通常需要提供一個原粒子，然後函數會回傳一個結構與原粒子相同但參數不同的粒子。\n",
    "\n",
    "下面是常用的隨機函數:\n",
    "\n",
    "**random_particle**\n",
    "\n",
    "    新粒子的參數會被隨機在0到1之間。\n",
    "    \n",
    "**normal_particle**\n",
    "\n",
    "    新粒子的參數會被隨機在一個標準常態分配。\n",
    "    \n",
    "**unit_particle**\n",
    "\n",
    "    新粒子的參數會被隨機，但全部參數會被限制在一個長度為1的狀態。\n",
    "    可以視新粒子為一參數空間中的單位向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584da568-3e8f-4f60-9a01-f955e50ed528",
   "metadata": {},
   "source": [
    "產生隨機性的粒子比較常見的其中一個用途就是用來繪製目標函數的長相，我們可以通過討整目標函數的設計，使得目標函數看起來更平滑或是更易於訓練。\n",
    "\n",
    "我們一樣以鳶尾花資料集為例，繪製不同目標函數的長相:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b0f832-5196-4a86-893a-adadd0e87988",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      3\u001b[0m iris \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_iris()     \u001b[38;5;66;03m# 載入資料\u001b[39;00m\n\u001b[1;32m      4\u001b[0m feature \u001b[38;5;241m=\u001b[39m iris\u001b[38;5;241m.\u001b[39mdata             \u001b[38;5;66;03m# 輸入的特徵資料\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()     # 載入資料\n",
    "feature = iris.data             # 輸入的特徵資料\n",
    "label = np.eye(3)[iris.target]  # 預測的類別資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f0948-68b6-42c7-a771-0ccdb0a10fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.shape, label.shape      # 查看數據的結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1dfd3-8290-4e24-b691-5daaa14f056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyto import unit_function as uf\n",
    "\n",
    "nn, node = to.new_net(\n",
    "    data_x = to.add_data(feature),\n",
    "    data_y = to.add_data(label),\n",
    "    layer1 = layer.new_nn_layer((4,6)),\n",
    "    layer2 = layer.new_nn_layer((6,3)),\n",
    ")\n",
    "\n",
    "node.layer1_output = node.data_x >> uf.col_nor() >> node.layer1 >> uf.tanh()\n",
    "node.layer2_output = node.layer1_output >> node.layer2 >> uf.softmax()\n",
    "node.pre = node.layer2_output\n",
    "\n",
    "node.cross_entropy = uf.cross_entropy(node.pre, node.data_y)\n",
    "node.MSE = uf.MSE(node.pre, node.data_y)\n",
    "node.MAE = uf.MAE(node.pre, node.data_y)\n",
    "\n",
    "node.loss = nn.launcher(node.cross_entropy, node.MSE, node.MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcbc061-1638-4028-b6ba-942af88c7a1e",
   "metadata": {},
   "source": [
    "使用`train_tool.unit_particle`來產生一個單位向量，並用該單位向量計算沿著該方向的各種loss值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935ea02-9aa0-4f22-a37a-2924fa918e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyto import train_tool as train\n",
    "\n",
    "unit_nn = train.unit_particle(nn) # 產生一個單位向量\n",
    "step_list = list(range(-10,11)) # 保存步長\n",
    "\n",
    "cross_entropy_list=[]\n",
    "MSE_list=[]\n",
    "MAE_list=[]\n",
    "for step in step_list:\n",
    "    new_nn = nn + step*unit_nn\n",
    "    new_node = to.create_connecter(new_nn)\n",
    "    \n",
    "    loss = get(new_node.loss)\n",
    "    cross_entropy_list.append(loss['cross_entropy'])\n",
    "    MSE_list.append(loss['MSE'])\n",
    "    MAE_list.append(loss['MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71907609-6ae2-46be-bb1a-d1a293c3dec6",
   "metadata": {},
   "source": [
    "繪製目標函數的長相:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3bab1-e4ff-4e37-a5a4-fea542ee9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(step_list,cross_entropy_list, label=\"CE\")\n",
    "plt.plot(step_list,MSE_list, label=\"MSE\")\n",
    "plt.plot(step_list,MAE_list, label=\"MAE\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada1ffa-cd6c-4552-b499-41daefa222c5",
   "metadata": {},
   "source": [
    "## 優化\n",
    "\n",
    "誠然使用者可以通過粒子運算自己打造自己的優化方式，但是如果有現成的工具可以使用何樂而不為呢？下面就來介紹nyto內建的優化網路工具。\n",
    "\n",
    "### dropout\n",
    "\n",
    "在深度學習中dropout算是十分重要的功能。要在nyto中使用dropout，有幾點要說明:\n",
    "1. nyto中的dropout的實現方式是通過dropconnect實現的。\n",
    "2. 必須在導入模型階段指定該模型是否需要啟用dropout。\n",
    "3. 啟用dropout後還需要在訓練時指定使用dropout訓練。\n",
    "4. 訓練完成後可以使用`trian_tool.inverse_dropout`調整參數。\n",
    "\n",
    "下面示範在導入模型時怎麼啟用dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf52627-7c51-4797-aeff-269f68c38f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn, node = to.new_net(\n",
    "    var=layer.new_variable_layer((2,2), dropout=True),\n",
    "    nn=layer.new_nn_layer((2,2), dropout=True),\n",
    "    lstm=layer.new_lstm_layer((2,2), input_data_dropout=True),\n",
    "    conv=layer.new_conv_layer((2,2), dropout=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f425c-44cc-4194-aef7-f28ab81749f5",
   "metadata": {},
   "source": [
    "啟用了dropout並不代表模型在訓練時是使用dropout的方式訓練的，還必須在訓練時使用dropout的功能。反之就算使用了dropout的方式訓練，但是模型並沒有啟用dropout，雖然也可以訓練，但是並不會有模型是使用dropout的方式訓練的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7af77-9eaa-4e40-877e-210f48c32616",
   "metadata": {},
   "source": [
    "### 池\n",
    "\n",
    "池可以簡單想成是有許多網路的一個集合，基於群體智彗的演算法往往需要使用大量的個體，這既是優點也是缺點。優點是由於搜索的範圍大，比較不容易陷入到不好的局部最佳中;缺點就是運算量大，收斂速度沒有基於梯度下降的方式快。\n",
    "\n",
    "nyto基於改良於粒子群演算法的演算法，可以在兩者中取得平衡。池中個體的數量將不再是那麼重要，使用者可以依據需要設定池的大小，即便池中只有一個個體，此時演算法依然可以正常運作，此時演算法的運作方式接近於梯度下降。如果遇到困難，可以將池變大，此時演算法接近於粒子群演算法。當然實際使用上不需要如此極端，池的大小只需要按個人需要使用即可。\n",
    "\n",
    "而要生成一個池可以使用*new_pool*函數產生，下面是介紹:\n",
    "\n",
    "**`new_pool`**\n",
    "\n",
    "    node_if:\n",
    "        需要優化的節點，優化的最終目標是讓該節點的輸出值最小。\n",
    "        資料型別是node_interface(節點界面)。\n",
    "\n",
    "    pool_size:\n",
    "        池大小,資料型別是int。\n",
    "\n",
    "    random_size:\n",
    "        亂數生成個體時常態分配的標準差，平均數為給定化節點的網路個體。\n",
    "        預設為1。\n",
    "\n",
    "    keep:\n",
    "        是否在池中保留原始網路，資料型別是bool。\n",
    "        預設為False。\n",
    " \n",
    "對於池，我們可以通過排名的順序查看不同個體，排名方式基於給定的優化節點。下面我們來生成一個池:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adb1c5-11a4-424f-ac84-43ee03c37e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成網路\n",
    "nn, n = to.new_net(\n",
    "    var=layer.new_variable_layer((2,2)),\n",
    "    np_sum=to.add_data(np.sum),\n",
    "    np_mean=to.add_data(np.mean)\n",
    ")\n",
    "\n",
    "# 建立需要優化的節點(可以有多個)\n",
    "n.sum = n.var.values() >> n.np_sum\n",
    "n.mean = n.var.values() >> n.np_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f1f5c-a37d-45e2-84b6-a4686e539e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成池\n",
    "pool = train.new_pool(n.sum, pool_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179f1d3-c10e-4e14-a2fb-8c85d42e556e",
   "metadata": {},
   "source": [
    "查看池的大小:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be0524-fb54-4205-af3b-048910646b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9008d86-21ae-4e40-b461-98188f09889f",
   "metadata": {},
   "source": [
    "取得優化值最小的網路:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c27a5f-5e51-422f-9831-8f247d6f15d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool.net[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f137cda8-2d58-49cc-b2e7-abef3bdb4b75",
   "metadata": {},
   "source": [
    "取得優化值前5名的網路:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e35a96a-81a5-406b-ae67-6b6d1380e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.net[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1040982-139c-4a9d-b44b-40dbe2923442",
   "metadata": {},
   "source": [
    "取得前5名的優化值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf3ee6-16cb-495a-9793-5bdd11593fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.loss[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d6cd3-4fef-4d61-aa94-f4c6d381c11a",
   "metadata": {},
   "source": [
    "將前5名的網路分割成一個新的池:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a278582-20bd-4557-92e2-014b7e1714c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pool = pool[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c502a0-ba0c-4e48-a299-dc43e289df5b",
   "metadata": {},
   "source": [
    "修改池中優化值所對應的節點名稱:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c319418-72a6-477b-8df6-1c3271da4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_with_node_mean = pool.reset_node_id(node_id='mean')\n",
    "\n",
    "pool.loss[0], pool_with_node_mean.loss[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d76bc9-2b31-4bc8-803f-9a2b501d6343",
   "metadata": {},
   "source": [
    "在池中每網路都有一個編號，編號從0開始依序分配給每個網路。如果想要取得按編號排序的網路組，可以使用`net.real`屬性，該屬性會回傳一個按實際編號排序的網路參考的list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d79d7-6103-4a59-a3f7-b3677b5ae843",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.net.real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b84fd-d76c-47db-bafb-b8cd248c9199",
   "metadata": {},
   "source": [
    "如果想取得按實際編號排序的優化值可以使用`loss.real`屬性，該屬性會回傳一個按實際編號排序的優化值的list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9e493-de18-46b7-a12c-144403644a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.loss.real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e28b0-ee81-4868-9a0e-ba79ec9fb6b9",
   "metadata": {},
   "source": [
    "**替換網路**\n",
    "\n",
    "可以使用`net`或是`real_net`對池中的網路進行網路的替換，前者是按優化值排序定位網路，後者是按實際編號定位網路:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf04fa-e146-461c-b1c9-ca10346f8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.net[0] = -pool.net[0]\n",
    "pool.real_net[0] = -pool.real_net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1eaa52-08ae-4b3d-9d9b-c4bb30c43a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.loss.real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e3192-61a1-49cc-9221-b9b910ae22ee",
   "metadata": {},
   "source": [
    "**`替換網路注意事項`**\n",
    "\n",
    "雖然看起來`pool.net.real`與`pool.real_net`用法好像差不多，但事實上有很大的不同。如果使用`pool.net.real`替換了網路，則替換進來網路的loss並不會被更新。\n",
    "\n",
    "而使用`pool.net[]`和`pool.real_net[]`更新網路後都會重新計算該網路的loss值。\n",
    "\n",
    "如果覺得複雜，只需要記得只使用`pool.real_net`替換網路即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18db1b0-7219-47e6-ac39-c0500af46c93",
   "metadata": {},
   "source": [
    "**`pool_apply`**\n",
    "\n",
    "對於很多時候來說，手動一個一個替換池中的網路可能不是很優雅的一種方式。然而很多時候我們會需要這麼做，比如我們需要將池中的所有網路對池外的網路做粒子運算。下面是使用手動替換的作法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b364e-9e04-434d-a808-632b7725535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nn, n) = to.new_net(data=layer.np_to_variable_layer(np.array([0])))\n",
    "n.loss = n.data.values().sum()\n",
    "\n",
    "pool = train.new_pool(n.loss, pool_size=5, keep=True)\n",
    "print(f'pool loss before:\\n {pool.loss.real[:]}')\n",
    "\n",
    "opt_nn = nn + 1\n",
    "for idx in range(len(pool)):\n",
    "    pool.real_net[idx] += opt_nn\n",
    "    \n",
    "print(f'pool loss after:\\n {pool.loss.real[:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b0ade-d88f-472d-b14e-4cf57775b665",
   "metadata": {},
   "source": [
    "下面是使用`pool_apply`的作法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd8413-b0b3-4db9-b409-21ad336638d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nn, n) = to.new_net(data=layer.np_to_variable_layer(np.array([0])))\n",
    "n.loss = n.data.values().sum()\n",
    "\n",
    "pool = train.new_pool(n.loss, pool_size=5, keep=True)\n",
    "print(f'pool loss before:\\n {pool.loss.real[:]}')\n",
    "\n",
    "opt_nn = nn + 1\n",
    "new_pool = pool.pool_apply(lambda nn: nn+opt_nn)\n",
    "print(f'new pool loss after:\\n {new_pool.loss.real[:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec869c0d-0560-467d-bbae-960b38accaa6",
   "metadata": {},
   "source": [
    "使用`pool_apply`需要傳入一個函數，池會將池中所有的網路都通過該函數後得到新網路。並將新網路保裝到新的池中，新網路在新池中的實際編號會與原池一樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96385c-7043-48d6-b7d7-23d968e9b9ec",
   "metadata": {},
   "source": [
    "### 優化池\n",
    "\n",
    "當池被生成出來後就可以使用優化函數優化整個池，優化結束時池中的不同個體的結果都是不同的，使用者可以使用池中最優秀的個體當成結果，也可以取前幾名當成結果，甚至可以在預測時讓池中的個體們投票的方式決定預測結果。\n",
    "\n",
    "與網路一樣，池本身也是一種粒子，所以也可以進行粒子運算:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7c05d-e95c-44d3-87a9-8ff20b0d40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pool = pool + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98566-2f18-434b-b4f8-dde1cc45ea46",
   "metadata": {},
   "source": [
    "雖然可以對池做粒子運算很令人興奮，但是如果要優化池中的網路，建議使用池優化器來進行優化。目前內建的池優化器有`epso_opt`，該演算法是基於粒子群算法改良的算法。下面是對相關參數的介紹:\n",
    "\n",
    "**`trian_tool.epso_opt`**\n",
    "\n",
    "    threshold:\n",
    "        擇優的門檻，越小越嚴格，為一大於0的值。預設1。\n",
    "\n",
    "    dropout_rate:\n",
    "        dropout的機率，為None時則為不dropout。\n",
    "        預設None。\n",
    "\n",
    "    step_rate:\n",
    "        單次訓練優化的程度，介於0到1之間。預設是1。\n",
    "        使用批訓練時，可以調小該值，降低訓練速度防止過度擬合部份資料。\n",
    "\n",
    "    bound:\n",
    "        優化上下界限，防止訓練時參數突然變化過大，當為None時為不設限。\n",
    "        預設100。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e108ef-1f5e-4c7e-914e-ba0b3bcb39f6",
   "metadata": {},
   "source": [
    "\n",
    "當優化器進行優化時，如果遇到需要使用批訓練的狀況時，可以使用`train_batch`函數來省去切換啟動器節點的部份代碼，下面是各參數的說明:\n",
    "\n",
    "`trian_tool.train_batch`\n",
    "\n",
    "    batch_node_list:\n",
    "        裝有啟動器節點的list，該函數會自動切換list中的節點，來替換池中的優化節點名稱。\n",
    "        當全部啟動器節點被替換過一次稱之為一個epoch，切換一個啟動器節點稱之為一個step。\n",
    "        當epoch結束時，step重新計算。\n",
    "\n",
    "    pool:\n",
    "        要優化的池。\n",
    "\n",
    "    opt:\n",
    "        使用的優化器。\n",
    "\n",
    "    step:\n",
    "        每訓練幾個step回傳一次結果。預設是1。\n",
    "\n",
    "    epoch:\n",
    "        總共訓練幾個epoch，預設為1。\n",
    "    \n",
    "函數回傳的結果為一迭代器，迭代器回傳3個值，分別為:\n",
    "1. (ep, idx): 為第幾個epoch和第幾個step\n",
    "2. new_pool: 優化後的池\n",
    "3. opt: 當前使用的優化器，可以隨時更新優化器\n",
    "\n",
    "當迭代器結束時，會回傳最後一次然後結束。使用起來大概像下面這樣:\n",
    "\n",
    "    for t,new_pool,opt in train_batch(batch_node_list, pool, opt):\n",
    "    \n",
    "        (ep, idx)=t\n",
    "        \n",
    "        # do something...\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d4885-8971-4f55-9063-072aade7c9d9",
   "metadata": {},
   "source": [
    "### dropout還原\n",
    "\n",
    "當使用dropout訓練結束時，我們需要將模型的權重根據dropout rate來調整成可以直接使用的狀態。在nyto中使用`inverse_dropout`來調整:\n",
    "\n",
    "**`trian_tool.inverse_dropout`**\n",
    "\n",
    "    nn:\n",
    "        需要調整的網路\n",
    "\n",
    "    dropout_rate:\n",
    "        訓練時使用的dropout rate。\n",
    "    \n",
    "函數回傳結果是一個調整後的網路。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eae2b5-f8d0-4a26-a9fb-d3c5de7361d5",
   "metadata": {},
   "source": [
    "## 固定模型\n",
    "\n",
    "有時候訓練的時候我們想要固定住某些模型的參數，而只訓練其他模型的參數該時，可以使用`net_tool.fix_mod`來固定，這時該粒子將無法被進行任何的粒子運算，自然也就不會參與到優化中了。而當想解除固定時，則可以使用`net_tool.unfix_mod`來解除固定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6552d6-e71a-42cb-bf9c-e76f7e2f173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn, node = to.new_net(\n",
    "    fixed_mod=layer.np_to_variable_layer(np.arange(5)),\n",
    "    unfixed_mod=layer.np_to_variable_layer(np.arange(5))\n",
    ")\n",
    "\n",
    "# 對網路中的模型fixed_mod進行固定\n",
    "to.fix_mod(nn, 'fixed_mod')\n",
    "\n",
    "# 查看固定前的狀態\n",
    "to.get(node.fixed_mod, node.unfixed_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2e5f9-81cd-4d3a-b677-73e1b6df7850",
   "metadata": {},
   "source": [
    "比較固定與沒固定的模型在進行粒子運算的前後差異，可以發現只有沒被固定的模型進行了運算:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12eceb-6a44-4ba9-b2a3-b3b79fb93671",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn = nn + 10\n",
    "new_nn_node = to.create_connecter(new_nn)\n",
    "\n",
    "to.get(new_nn_node.fixed_mod, new_nn_node.unfixed_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482d778-2b83-447b-9d56-7f9e0e7961d4",
   "metadata": {},
   "source": [
    "可以使用`net.info.mod_is_fix`確認網路中的模型是否被固定:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34939b-d6c4-4ca6-9967-4c37f8a075ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.info.mod_is_fix('fixed_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a67e9-80f1-4bda-8805-f354adc855f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.info.mod_is_fix('unfixed_mod')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5b603-8736-4655-a2b5-c117e50f6f26",
   "metadata": {},
   "source": [
    "使用`net_tool.unfix_mod`解除固定:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439532d-591f-42be-afc0-cc7184b3ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "to.unfix_mod(nn, 'fixed_mod')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f556d0-fe8f-4e02-82b5-97cfc4a1115e",
   "metadata": {},
   "source": [
    "確認模型是否已經被解除固定:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec8f96-1a53-40da-9961-bd2af3546d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.info.mod_is_fix('fixed_mod')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944c724-58de-462a-abd9-6bf850d0890e",
   "metadata": {},
   "source": [
    "也可以在層模型生成後直接固定:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5803ee-c1f3-41c9-b211-4e62eaeae239",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mod = layer.new_nn_layer((2,2))\n",
    "nn_mod.fix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cc9a6-9a85-4904-8e18-62d67338c588",
   "metadata": {},
   "source": [
    "也可以直接確認該模型是否被固定:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259bdbf-f1fa-42d6-8e1d-b1c901880a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mod.is_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0832aa5-d285-4f16-8009-7f9169548809",
   "metadata": {},
   "source": [
    "還有解除固定:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88ca98-1048-4dad-a2d8-0b77e33c1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mod.unfix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d18c3b-3ff3-4a8c-b717-617c81277feb",
   "metadata": {},
   "source": [
    "## 結語\n",
    "\n",
    "到此nyto的使用方法已經介紹完畢，希望大家能用的開心。\n",
    "\n",
    "***\n",
    "\n",
    "*END*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
