{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfc529a-bd4b-4ab5-8427-b0fdb84b59af",
   "metadata": {},
   "source": [
    "# ch4 函數與模型\n",
    "\n",
    "使用節點可以組織出複雜的運算系統，但節點也只是起了連接網路內各個元件的功能而已。支撐起整套運算系統的核心是模型和函數，下面我們就來簡單介紹一下兩者的差別:\n",
    "\n",
    "**`函數:`**\n",
    "1. 定義在unit_function模組中，功能是提供一些常見的函數，比如:tanh或是cross_entropy。\n",
    "2. 使用時不需要事先導入到網路，直接在建立連接時使用即可。\n",
    "3. 函數沒有需要優化的參數所以屬於資料節點。\n",
    "\n",
    "**`模型:`**\n",
    "1. 定義在layer模組中，功能是提供一些常見的(單層)類神經網路模型，比如:CNN或LSTM\n",
    "2. 使用時需要導入到網路，否則運行節點時會保錯。\n",
    "3. 模型需要優化的參數所以屬於模型節點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4a528c4-4536-41b8-be4c-549700807f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyto import unit_function as uf\n",
    "from nyto import layer\n",
    "from nyto import net_tool as to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffe3b9-fb81-4a6c-a6f0-c32a2d5f32fa",
   "metadata": {},
   "source": [
    "## 函數\n",
    "\n",
    "函數有嚴格的使用規定，主要分成支援右移運算和不支援右移運算兩種，支援右移運算的可以寫成下面兩種形式:\n",
    "\n",
    "    [1] node1 >> function(param,) >> node2\n",
    "    [2] node2 = function(param,)(node1)\n",
    "\n",
    "不支援右移運算只能寫成下面這種形式:\n",
    "    \n",
    "    [1] function(node1, param,) >> node2\n",
    "    [2] node2 = function(node1, param,)\n",
    "    \n",
    "通常不支援右移運算的函數都是需要輸入兩個或兩個節點以上的函數，所以無法支援右移運算。\n",
    "\n",
    "**`支援右移運算:`**\n",
    "* linear()\n",
    "* relu()\n",
    "* gaussian()\n",
    "* sigmoid()\n",
    "* tanh()\n",
    "* col_nor()\n",
    "* row_nor()\n",
    "* softmax()\n",
    "* global_average_pooling()\n",
    "* global_max_pooling()\n",
    "* flattening()\n",
    "* max_pooling(kernel_shape_node_if, strides=1)\n",
    "* average_pooling(kernel_shape_node_if, strides=1)\n",
    "\n",
    "**`不支援右移運算:`**\n",
    "* concatenate(*node_ifs, axis=1)\n",
    "* tile(node_if, size_tuple)\n",
    "* MSE(pre_if, target_if)\n",
    "* RMSE(pre_if, target_if)\n",
    "* MAE(pre_if, target_if)\n",
    "* MAPE(pre_if, target_if)\n",
    "* cross_entropy(pre_if, target_if)\n",
    "* binary_cross_entropy(pre_if, target_if)\n",
    "* accuracy(pre_if, target_if)\n",
    "\n",
    "由於大部份的函數使用上都算直覺，這邊就挑幾個說明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b669179-7366-47c1-9301-053827c5207c",
   "metadata": {},
   "source": [
    "### max_pooling和average_pooling\n",
    "\n",
    "這兩個函數是卷集神經網路會用到的pooling函數，需要調整的參數為:\n",
    "* (tuple/node_interface)kernel_shape_node_if: 窗口的尺寸，比如(3,3)，也可以輸入一個節點界面。\n",
    "* (int/node_interface)strides=1: 窗口移動的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "16665026-2699-4213-8a4a-0e1180badad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nyto.net.node_interface at 0x7f62f35eaf90>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nn,n = to.new_net(\n",
    "    # 輸入的圖片是4維的numpy.array\n",
    "    # [第幾筆資料][channel][圖片row][圖片col]\n",
    "    img_np = to.add_data(np.arange(2*3*5*5).reshape(2,3,5,5)),\n",
    "    kernal_shape=(3,3),\n",
    "    strides=1\n",
    ")\n",
    "\n",
    "n.img_np >> uf.max_pooling(n.kernal_shape, n.strides) >> n.max_pooling\n",
    "n.img_np >> uf.average_pooling((3,3), strides=1) >> n.average_pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845fe6c-eac3-44af-8340-0cd7b7c2dd0a",
   "metadata": {},
   "source": [
    "### concatenate和tile\n",
    "\n",
    "這兩個函數是用來拼接numpy.array用的可以對應到numpy的函數:\n",
    "* concatenate(*node_ifs, axis=1) -> np.concatenate(node_ifs, axis=axis)\n",
    "* tile(node_if, size_tuple) -> np.tile(node_if, size_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0825d7c6-bbb3-4ad3-8cad-1d023bcad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn,n = to.new_net(\n",
    "    data1 = np.arange(9).reshape(3,3),\n",
    "    data2 = np.arange(9,18).reshape(3,3),\n",
    "    size_tuple = (3,2)\n",
    ")\n",
    "\n",
    "n.data3 = uf.concatenate(n.data1, n.data2)\n",
    "n.data4 = uf.tile(n.data1, size_tuple=n.size_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0156f3ce-3a77-46d5-8a3a-fa2dbb7b7749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  9, 10, 11],\n",
       "       [ 3,  4,  5, 12, 13, 14],\n",
       "       [ 6,  7,  8, 15, 16, 17]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.get(n.data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ec8b7bd-a254-4422-bf85-fadcb0d8d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1, 2],\n",
       "       [3, 4, 5, 3, 4, 5],\n",
       "       [6, 7, 8, 6, 7, 8],\n",
       "       [0, 1, 2, 0, 1, 2],\n",
       "       [3, 4, 5, 3, 4, 5],\n",
       "       [6, 7, 8, 6, 7, 8],\n",
       "       [0, 1, 2, 0, 1, 2],\n",
       "       [3, 4, 5, 3, 4, 5],\n",
       "       [6, 7, 8, 6, 7, 8]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.get(n.data4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c4813-4ac6-4a3f-9f25-1a61a8d57596",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型\n",
    "\n",
    "下面來介紹模型，這邊需要注意的是前面我們介紹過模型節點，所謂的模型節點就是裡面保存了模型的節點。而模型節點最大的特點就是模型是可以被優化的，不能被優化的我們一般會被放到資料節點中。\n",
    "\n",
    "這邊我們要做更近一步的說明了，首先:可以被優化的單元一定是模型，但模型不一定可以被優化。也就是說模型中其實也存在可以優化的模型與不能優化的模型。你可能會感到困惑，那資料與模型的差別在於什麼呢？\n",
    "\n",
    "模型與資料的真正定義是:\n",
    "> 可以被多個網路共享的單元為資料，各網路獨有的單元為模型\n",
    "\n",
    "這說明模型與資料的差別並不是簡單的能不能優化而已，而在模型中存在著可以被優化與不能被優化的模型，我們將可以優化的模型稱為層模型(layer)。層模型被定義在`layer`模組中，有以下幾個成員:\n",
    "1. variable_layer: 單純的矩陣，一般用於尋找最佳的輸入\n",
    "2. nn_layer:       單層的類神經網路\n",
    "3. lstm_layer:     單層的LSTM\n",
    "4. conv_layer:     單層卷集層，裡面有多個keranl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c643d1b-7dc6-4ae5-82b3-eb05c3ff4c64",
   "metadata": {},
   "source": [
    "### variable_layer\n",
    "\n",
    "作為一個可優化的矩陣，能做到的事情遠比看上去的多。基本上，另外3種的層模型都可以使用該層去做出來，只不過會犧牲執行的效率。可以使用*layer.new_variable_layer*函數產生，下面是各項參數的說明:\n",
    "\n",
    "**`layer.new_variable_layer`**\n",
    "\n",
    "**structure**\n",
    "    \n",
    "    生成矩陣的形狀，資料型別是tuple。\n",
    "    exp:(3,2)\n",
    "**init_values**\n",
    "    \n",
    "    亂數生成時常態分配的平均數，預設0。\n",
    "**random_size**\n",
    "    \n",
    "    亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    預設None。\n",
    "**dropout**\n",
    "\n",
    "    使用dropout訓練時是否啟用dropout，預設False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4ebadac-8fb3-44f4-8070-24e412e98535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((3, 4))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_mod = layer.new_variable_layer((3,4))\n",
    "variable_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49537167-b665-4d41-8ce5-763f53600f25",
   "metadata": {},
   "source": [
    "可以使用`shape`方法查看模型的形狀:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c2a59ab5-78d8-42fe-ad15-cc7804e7657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_mod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a880ea1-9d09-4916-9ef5-30f88f89612d",
   "metadata": {},
   "source": [
    "可以使用`values`方法查看並修改模型參數:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8334f91-eb55-4e93-b324-d885ea850f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_mod.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ebea8-45b3-4064-a43d-84647f647167",
   "metadata": {},
   "source": [
    "如果你手邊有一個已經準備好的`numpy.array`，你可以使用*layer.np_to_variable_layer*轉換成`variable_layer`，下面是該函數的參數:\n",
    "\n",
    "**`layer.np_to_variable_layer`**\n",
    "\n",
    "**variable_np**\n",
    "    \n",
    "    要被轉換的numpy.array。    \n",
    "**dropout**\n",
    "\n",
    "    使用dropout訓練時是否啟用dropout，預設False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59be45f0-f3e7-4f95-88b4-e3a9cd8aba30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((3, 4))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_mod=layer.np_to_variable_layer(variable_np=np.arange(12).reshape(3,4))\n",
    "variable_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "45ea1e7b-412a-452c-9b56-e974991fc120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_mod.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c61ac-0afc-4ec5-b1c7-d3ab63c80045",
   "metadata": {},
   "source": [
    "需要注意的是`variable_layer`在網路中被執行時，如果需要與其他的不是層模型的模型互動時，建議先轉換成np.array。\n",
    "\n",
    "與其他層模型互動時，不需要傳換:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b28cf0d8-75d2-4914-af79-9a7fe10eeea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(variable_layer((3, 3)),\n",
       " array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn,n = to.new_net(\n",
    "    var1_layer=layer.new_variable_layer((3,3), 1), \n",
    "    var2_layer=layer.new_variable_layer((3,3), 2),\n",
    "    nn_layer=layer.new_nn_layer((3,3)),\n",
    "    data_np=np.arange(9).reshape(3,3)\n",
    ")\n",
    "\n",
    "n.interact_with_other_layer1 = n.var1_layer + n.var2_layer\n",
    "n.interact_with_other_layer2 = n.var1_layer >> n.nn_layer\n",
    "\n",
    "to.get(n.interact_with_other_layer1, n.interact_with_other_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafcb7e4-b757-4b49-a917-2f42bdcd5bea",
   "metadata": {},
   "source": [
    "與非層模型互動時，可以先使用`values`方法取出模型中的參數:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90c2cb07-1cd4-4a02-8507-de6a05a2a465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.use_values_to_get_np = n.var1_layer.values() + n.data_np\n",
    "to.get(n.use_values_to_get_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1205b7-6425-44dc-80f7-0c6b5ba7b1b9",
   "metadata": {},
   "source": [
    "### nn_layer\n",
    "\n",
    "單層的神經網路，可以用來組合出複雜的網路結構，可以使用*layer.new_nn_layer*產生:\n",
    "\n",
    "**`layer.new_nn_layer`**\n",
    "\n",
    "**structure**\n",
    "\n",
    "    網路結構，資料型別是tuple。\n",
    "    第一格是網路的輸入大小，第一格是網路的輸出大小。\n",
    "    exp:(3,2)  \n",
    "**init_values**\n",
    "\n",
    "    亂數生成時常態分配的平均數，資料型別是tuple，預設為(0,0)。\n",
    "    第一格是網路權重的平均數，第二格是網路偏置的平均數。\n",
    "**random_size**\n",
    "\n",
    "    亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    第一格是網路權重的標準差，第二格是網路偏置的標準差。\n",
    "    預設為(None, None)。\n",
    "**dropout**\n",
    "    \n",
    "    使用dropout訓練時是否啟用dropout，預設True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea9dba94-7a48-4f5e-8b48-c82a189bac85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn_layer((2, 3))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_mod = layer.new_nn_layer((2,3))\n",
    "nn_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c507-6e6c-443c-9b4e-f40f85ca9053",
   "metadata": {},
   "source": [
    "可以使用`weights`和`bias`方法取得並修改權重與偏置的參數:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "07e0f5aa-24e0-4627-a550-8dadfc71717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_mod.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b462565-a6c0-4c25-bc19-501826d740fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_mod.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8979db-6503-4124-ba85-42244e17075f",
   "metadata": {},
   "source": [
    "可以使用`__call__`方法來對輸入的np.array做運算:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b5dcacde-51f3-4a6a-88a4-35eb700c7e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np = np.arange(6).reshape(3,2)\n",
    "nn_mod(data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d0b75-5692-4ac2-b231-3985d28505ea",
   "metadata": {},
   "source": [
    "### lstm_layer\n",
    "\n",
    "單層的神經網路，可以用來對時間序列分析，可以使用*layer.new_lstm_layer*產生:\n",
    "\n",
    "**`layer.new_lstm_layer`**\n",
    "\n",
    "**structure**\n",
    "\n",
    "    網路結構，資料型別是tuple。\n",
    "    第一格是網路的輸入大小，第二格是網路的輸出大小。\n",
    "    exp:(3,2)  \n",
    "**compute_init**\n",
    "\n",
    "    compute計算單元網路參數亂數生成時常態分配的平均數，資料型別是tuple，預設為(0,0)。\n",
    "    第一格是網路權重的平均數，第二格是網路偏置的平均數。\n",
    "**compute_random**\n",
    "\n",
    "    compute計算單元網路參數亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    第一格是網路權重的標準差，第二格是網路偏置的標準差。\n",
    "    預設為(None, None)。\n",
    "**input_init**\n",
    "\n",
    "    input gate計算單元網路參數亂數生成時常態分配的平均數，資料型別是tuple，預設為(0,0)。\n",
    "    第一格是網路權重的平均數，第二格是網路偏置的平均數。\n",
    "**input_random**\n",
    "\n",
    "    input gate計算單元網路參數亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    第一格是網路權重的標準差，第二格是網路偏置的標準差。\n",
    "    預設為(None, None)。\n",
    "**output_init**\n",
    "\n",
    "    output gate計算單元網路參數亂數生成時常態分配的平均數，資料型別是tuple，預設為(0,0)。\n",
    "    第一格是網路權重的平均數，第二格是網路偏置的平均數。\n",
    "**output_random**\n",
    "\n",
    "    output gate計算單元網路參數亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    第一格是網路權重的標準差，第二格是網路偏置的標準差。\n",
    "    預設為(None, None)。\n",
    "**forget_init**\n",
    "\n",
    "    forget gate計算單元網路參數亂數生成時常態分配的平均數，資料型別是tuple，預設為(0,0)。\n",
    "    第一格是網路權重的平均數，第二格是網路偏置的平均數。\n",
    "**forget_random**\n",
    "\n",
    "    forget gate計算單元網路參數亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    第一格是網路權重的標準差，第二格是網路偏置的標準差。\n",
    "    預設為(None, None)。\n",
    "**state_init**\n",
    "\n",
    "    預設初始狀態(memory cell)參數亂數生成時常態分配的平均數，預設為0。\n",
    "**state_random**\n",
    "\n",
    "    預設初始狀態(memory cell)參數亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    預設為None。\n",
    "**input_data_dropout**\n",
    "    \n",
    "    連接輸入feature的權重是否啟用dropout，預設True。\n",
    "**mem_data_dropout**\n",
    "    \n",
    "    連接輸入memory cell的權重是否啟用dropout，預設False。\n",
    "**reinput_data_dropout**\n",
    "    \n",
    "    連接輸入上個時間點書出的權重是否啟用dropout，預設True。\n",
    "**com_func**\n",
    "    \n",
    "    compute計算單元的activation function，預設為tanh\n",
    "**ingate_func**\n",
    "    \n",
    "    input gate計算單元的activation function，預設為sigmoid\n",
    "**outgate_func**\n",
    "    \n",
    "    output gate計算單元的activation function，預設為sigmoid\n",
    "**forgate_func**\n",
    "    \n",
    "    forget gate計算單元的activation function，預設為sigmoid\n",
    "**final_func**\n",
    "    \n",
    "    lstm模型輸出時的activation function，預設為tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a780d58f-0a34-48e3-92ed-5a1db4fa4743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstm_layer((2, 1))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_mod = layer.new_lstm_layer((2,1))\n",
    "lstm_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a499a10-684a-432c-8d17-13c2f5681fc6",
   "metadata": {},
   "source": [
    "下面是常用的模型參數與方法:\n",
    "1. shape: 模型的形狀(輸入大小,輸出大小)\n",
    "2. init_mem: 預設初始memory call參數(variable_layer)\n",
    "3. init_out: 預設初始reinput_data參數(variable_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed5125ce-78dd-4595-8255-4f8b453b98ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((1, 1))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_mod.init_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5df89823-bb38-456e-ad46-c14927974c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_layer((1, 1))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_mod.init_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3309c60-ae3d-466f-9cc2-e7b6c97d341b",
   "metadata": {},
   "source": [
    "**`lstm運算`**\n",
    "\n",
    "lstm的運算根據輸入資料的情況分成3種模式:\n",
    "1. 單筆(run): 只計算某個時間點，不僅需要輸入特徵資料，還需要memory cell與reinput_data。\n",
    "2. 多筆(run_series): 計算時間序列，只需要輸入特徵資料，memory cell與reinput_data會自動計算。\n",
    "3. 批(__call__): 計算批資料。\n",
    "\n",
    "下面是計算單筆的範例，計算結果會回傳lstm的結果和新的memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d4c62405-6a39-439b-ad58-0cd34f128967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.]]), array([[0.]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_np = np.array([[1,0]])\n",
    "memory_np = lstm_mod.init_mem.values\n",
    "reinput_data = lstm_mod.init_out.values\n",
    "\n",
    "final_np, new_mem = lstm_mod.run(in_np=feature_np, mem_np=memory_np, out_np=reinput_data)\n",
    "final_np, new_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16bab1-ed16-436b-8459-fdf17628895e",
   "metadata": {},
   "source": [
    "下面是計算多筆的範例，計算結果會回傳lstm的各時間點的結果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "294f2e7a-e41d-4d84-baed-9aa3cd6630bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_np = np.arange(10).reshape(5,2)\n",
    "lstm_mod.run_series(feature_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230e74f-4b58-42d8-9dcb-5ad9461b582f",
   "metadata": {},
   "source": [
    "下面是計算批的範例，計算結果會回傳lstm的各批在各時間點的結果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4315d6e6-4a95-4d09-87f0-880e52d362e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1 = np.arange(6).reshape(3,2)\n",
    "batch2 = np.arange(10).reshape(5,2)\n",
    "total_batch = [batch1, batch2]\n",
    "\n",
    "lstm_mod(total_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15357e9f-29b3-4031-8758-62059233eab4",
   "metadata": {},
   "source": [
    "### conv_layer\n",
    "\n",
    "單層的卷集層，可以用來對圖像資料分析，可以使用*layer.new_conv_layer*產生:\n",
    "\n",
    "**`layer.new_conv_layer`**\n",
    "\n",
    "**structure**\n",
    "\n",
    "    filter結構，資料型別是tuple。\n",
    "    第一格是input大小，第二格是output大小。\n",
    "    exp:(1,2)\n",
    "**kernal_size**\n",
    "    \n",
    "    kernel結構，資料型別是tuple，預設(3,3)。\n",
    "    第二格是kernel的row大小,第三格是kernel的col大小。\n",
    "**init_values**\n",
    "\n",
    "    亂數生成時常態分配的平均數，預設0。\n",
    "**random_size**\n",
    "\n",
    "    亂數生成時常態分配的標準差,為None時則使用init_values作為預設值。\n",
    "    預設None。\n",
    "**dropout**\n",
    "    \n",
    "    使用dropout訓練時是否啟用dropout，資料型別是bool。\n",
    "    預設False。\n",
    "    \n",
    "**pad_mod**\n",
    "\n",
    "    padding模式，有三種選擇:(1)'full'(2)'valid'(3)'same'\n",
    "    'same'=不做padding，預設為'valid'\n",
    "    \n",
    "**strides**\n",
    "\n",
    "    窗口移動大小，資料型別是int。\n",
    "    預設為1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "24a95caa-8d7d-4a56-81eb-f1d621c8e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_layer(((1, 2), (3, 3)))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn=layer.new_conv_layer((1,2))\n",
    "cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47947647-db74-4780-9710-4ad655bb1e14",
   "metadata": {},
   "source": [
    "可以使用`shape`查看模型的形狀:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "73338b85-8e95-4ca2-a895-dcac07a96800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), (3, 3))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_shape, kernal_shape = cnn.shape\n",
    "filter_shape, kernal_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1735691-a935-4c92-9cd8-d74ef51ebda6",
   "metadata": {},
   "source": [
    "可以使用`filter_np`查看或修改filter的參數:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5cd498e8-1675-4902-8c62-4df2e445a164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.filter_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58b30e-03aa-4e72-88df-dc340e5e69d0",
   "metadata": {},
   "source": [
    "`CNN計算`\n",
    "\n",
    "輸入到conv_layer的圖片資料必須是一個4維的np.array的資料格式，由外到內分別是:\n",
    "1. 第幾筆資料\n",
    "2. 圖片的channel(feature)\n",
    "3. 圖片的row\n",
    "4. 圖片的column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1f85c766-1a21-46c3-9b62-1ce217832b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_np[2, 1, 3, 3]\n",
    "# 2筆資料\n",
    "# 1個channel\n",
    "# row = 3\n",
    "# column = 3\n",
    "img_np = np.array([\n",
    "    [\n",
    "        [\n",
    "            [0, 1, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 1, 0],\n",
    "        ]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [0, 0, 0],\n",
    "            [1, 1, 1],\n",
    "            [0, 0, 0],\n",
    "        ]\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572e3b3e-3ba3-4cf7-96a8-88fa96f8c16c",
   "metadata": {},
   "source": [
    "cnn會將圖片的一個channal，提取出2個feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "267cdfa9-2a6a-49da-af95-abc7cbd2cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_np = cnn(img_np)\n",
    "ret_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31fbba-b30f-4507-9a20-fd351d9c8e12",
   "metadata": {},
   "source": [
    "使用不同的pad_mod，所得到的輸出尺寸將不同:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5112df89-2dfb-4d78-a0a3-4540286e85f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1, 1, 1), (2, 1, 3, 3), (2, 1, 5, 5))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_pad_cnn = layer.new_conv_layer((1,1), pad_mod='same')\n",
    "valid_pad_cnn = layer.new_conv_layer((1,1), pad_mod='valid')\n",
    "full_pad_cnn = layer.new_conv_layer((1,1), pad_mod='full')\n",
    "\n",
    "same_pad_cnn(img_np).shape, valid_pad_cnn(img_np).shape, full_pad_cnn(img_np).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b689d-88bf-4368-b87a-151c71fb6c5c",
   "metadata": {},
   "source": [
    "## 子網路"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad13c4-218c-4f1a-8f6d-50c07e2f3c2e",
   "metadata": {},
   "source": [
    "如果你手邊正好有一個訓練好的網路，它能不能與其他網路組合起來變成一個更好的網路呢？被其他網路導入的網路我們稱之為子網路，我們可以使用`net.push_get`來在其他網路中完成對該網路的使用:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9a02d873-345a-47f4-9926-a990c279b8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 3}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 子網路\n",
    "sub_nn, sub_nn_node = to.new_net()\n",
    "sub_nn_node.y = sub_nn_node.x1 + sub_nn_node.x2\n",
    "\n",
    "# 導入子網路\n",
    "nn, node = to.new_net(a=1, b=2, sub_nn=sub_nn)\n",
    "node.sub_nn_return = node.sub_nn.push_get(\n",
    "    {'y'}, x1=node.a, x2=node.b\n",
    ")\n",
    "\n",
    "to.get(node.sub_nn_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cc62c-668e-40a9-bca3-0a6d824a19c2",
   "metadata": {},
   "source": [
    "對於子網路，我們應該要如何看待呢？可以簡單當成層模型來使用。當優化時，被導入的子網路也會如同網路內的其他層模型一樣被優化。但如果只想使用而不想優化子網路，最簡單的方法就是在導入時使用資料的方式導入。當然更簡單的方式也是有的，使用者可以很方便的切換是否需要優化子網路，我們在下一章中再做介紹。\n",
    "\n",
    "***\n",
    "\n",
    "*END*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
